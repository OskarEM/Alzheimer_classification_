{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b278b-1865-4ae7-b1e8-9f7fec5e96bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "import wandb\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # This line prevents TensorFlow from using GPU\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"computer_vision\", config={\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"architecture\": \"DenseNet121\",\n",
    "    \"dataset\": \"alzheimer\",\n",
    "    \"epochs\": 40,\n",
    "    \"batch_size\": 16,\n",
    "    \"input_shape\": (176, 208, 3),\n",
    "    \"num_classes\": 4\n",
    "})\n",
    "config = wandb.config\n",
    "\n",
    "class CustomWandbCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        wandb.log({\n",
    "            'epoch': epoch,\n",
    "            'loss': logs.get('loss', 0),\n",
    "            'accuracy': logs.get('accuracy', 0),\n",
    "            'val_loss': logs.get('val_loss', 0),\n",
    "            'val_accuracy': logs.get('val_accuracy', 0)\n",
    "        })\n",
    "\n",
    "# Function to load all images and labels\n",
    "def load_images_and_labels(dataset_path, target_size):\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    generator = datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=target_size[:2],\n",
    "        batch_size=config.batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False  # Important for maintaining label order for k-fold\n",
    "    )\n",
    "    images, labels = [], []\n",
    "    for _ in range(len(generator)):\n",
    "        img, lbl = next(generator)\n",
    "        images.append(img)\n",
    "        labels.append(lbl)\n",
    "    images = np.vstack(images)\n",
    "    labels = np.vstack(labels)\n",
    "    return images, labels\n",
    "\n",
    "# Load training and test data\n",
    "train_images, train_labels = load_images_and_labels('train', config.input_shape)\n",
    "test_images, test_labels = load_images_and_labels('test', config.input_shape)\n",
    "\n",
    "def create_densenet_model():\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_tensor=tf.keras.Input(shape=config.input_shape))\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(config.num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(learning_rate=config.learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_var = 1\n",
    "for train_index, val_index in kf.split(train_images):\n",
    "    x_train, x_val = train_images[train_index], train_images[val_index]\n",
    "    y_train, y_val = train_labels[train_index], train_labels[val_index]\n",
    "\n",
    "    model = create_densenet_model()\n",
    "\n",
    "    # Train model\n",
    "    checkpoint_path = f\"model_checkpoints/model_fold_{fold_var}.keras\"\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=config.epochs,\n",
    "        batch_size=config.batch_size,\n",
    "        callbacks=[checkpoint, CustomWandbCallback()]\n",
    "    )\n",
    "\n",
    "    # Evaluate on the test set after each fold\n",
    "    test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "    print(f\"Test Results - Loss: {test_loss}, Accuracy: {test_accuracy}\")\n",
    "    wandb.log({'test_loss_fold_'+str(fold_var): test_loss, 'test_accuracy_fold_'+str(fold_var): test_accuracy})\n",
    "\n",
    "    # Plot training and validation accuracy and loss\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Fold {fold_var} Training vs Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Fold {fold_var} Training vs Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    fold_var += 1\n",
    "\n",
    "# Close the WandB run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738feaa-0d9c-48de-ac9d-8d837f5dc31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the models\n",
    "model_1 = tf.keras.models.load_model('model_checkpoints/model_fold_1.keras')\n",
    "model_2 = tf.keras.models.load_model('model_checkpoints/model_fold_2.keras')\n",
    "model_3 = tf.keras.models.load_model('model_checkpoints/model_fold_3.keras')\n",
    "model_4 = tf.keras.models.load_model('model_checkpoints/model_fold_4.keras')\n",
    "model_5 = tf.keras.models.load_model('model_checkpoints/model_fold_5.keras')\n",
    "\n",
    "# Assuming test_datagen and test_generator are already defined as shown previously\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'test',  # Update this path to your test directory\n",
    "    target_size=(176, 208),  # Ensure these are the dimensions expected by your models\n",
    "    batch_size=16,           # Match this with the batch size used during training\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)           # Important to set shuffle to False for evaluation purposes\n",
    "\n",
    "# Predict the classes with the model\n",
    "predictions_1 = model_1.predict(test_generator)\n",
    "predictions_2 = model_2.predict(test_generator)\n",
    "predictions_3 = model_3.predict(test_generator)\n",
    "predictions_4 = model_4.predict(test_generator)\n",
    "predictions_5 = model_5.predict(test_generator)\n",
    "\n",
    "# Average the predictions for soft voting or choose other voting mechanism\n",
    "average_predictions = (predictions_1 + predictions_2 + predictions_3 + predictions_4 + predictions_5 ) / 5\n",
    "predicted_classes = np.argmax(average_predictions, axis=1)\n",
    "\n",
    "# Since the generator might shuffle the order of the data, the classes array needs to correspond correctly\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Evaluate the ensemble's accuracy manually if needed\n",
    "accuracy = np.mean(predicted_classes == true_classes)\n",
    "print(f\"Ensemble Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix for Ensemble')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adb0e01-f2e2-473d-925a-745ebe233819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries, and k-fold with gabor\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(project=\"computer_vision\", config={\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 16,\n",
    "    \"input_shape\": (176, 208, 3),\n",
    "    \"num_classes\": 4\n",
    "})\n",
    "config = wandb.config\n",
    "\n",
    "def load_images_and_labels(base_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {}\n",
    "    class_id = 0\n",
    "    for folder_name in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.lower().endswith((\".jpg\", \".png\")):\n",
    "                    img_path = os.path.join(folder_path, filename)\n",
    "                    img = load_img(img_path, target_size=(config.input_shape[0], config.input_shape[1]))\n",
    "                    img = img_to_array(img)\n",
    "                    img = preprocess_input(img)\n",
    "                    images.append(img)\n",
    "                    labels.append(class_id)\n",
    "            label_map[folder_name] = class_id\n",
    "            class_id += 1\n",
    "    return np.array(images), np.array(labels), label_map\n",
    "\n",
    "# Load training data\n",
    "dataset_path = 'alzheimer_gabor_8/train'\n",
    "images, labels, label_map = load_images_and_labels(dataset_path)\n",
    "labels = to_categorical(labels, num_classes=config.num_classes)\n",
    "\n",
    "def create_resnet_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=config.input_shape)\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(config.num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(config.learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_var, (train_idx, val_idx) in enumerate(kfold.split(images, np.argmax(labels, axis=1)), 1):\n",
    "    train_data, val_data = images[train_idx], images[val_idx]\n",
    "    train_labels, val_labels = labels[train_idx], labels[val_idx]\n",
    "    train_generator = ImageDataGenerator()\n",
    "    val_generator = ImageDataGenerator()\n",
    "    train_gen = train_generator.flow(train_data, train_labels, batch_size=config.batch_size)\n",
    "    val_gen = val_generator.flow(val_data, val_labels, batch_size=config.batch_size)\n",
    "\n",
    "    model = create_resnet_model()\n",
    "    checkpoint_path = f\"best_model_fold_{fold_var}_epoch{{epoch:02d}}_val_acc{{val_accuracy:.4f}}.keras\"\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "    # Adding WandbCallback to log metrics after each epoch\n",
    "    history = model.fit(train_gen, epochs=config.epochs, validation_data=val_gen, \n",
    "                        callbacks=[checkpoint])\n",
    "\n",
    "    # Optionally log summary data at the end of each fold\n",
    "    logs = {}\n",
    "    for metric in history.history:\n",
    "        logs[f'{metric}_fold_{fold_var}'] = history.history[metric][-1]\n",
    "    wandb.log(logs)\n",
    "\n",
    "# Load and preprocess test data\n",
    "test_path = 'alzheimer_gabor_8/test'\n",
    "test_images, test_labels, _ = load_images_and_labels(test_path)\n",
    "test_labels = to_categorical(test_labels, num_classes=config.num_classes)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_gen = test_datagen.flow(test_images, test_labels, batch_size=config.batch_size)\n",
    "\n",
    "final_checkpoint = 'final_best_model_epoch{epoch:02d}_val_acc{val_accuracy:.4f}.keras'\n",
    "final_model = create_resnet_model()\n",
    "final_checkpoint_callback = ModelCheckpoint(final_checkpoint, monitor='val_accuracy', save_best_only=True, verbose=1, mode='max')\n",
    "final_model.fit(images, labels, epochs=config.epochs, batch_size=config.batch_size, validation_data=test_gen, callbacks=[final_checkpoint_callback])\n",
    "\n",
    "best_final_model = tf.keras.models.load_model(final_checkpoint)\n",
    "test_loss, test_accuracy = best_final_model.evaluate(test_gen)\n",
    "print(f'Final Test loss: {test_loss}, Test accuracy: {test_accuracy}')\n",
    "wandb.log({'final_test_loss': test_loss, 'final_test_accuracy': test_accuracy})\n",
    "\n",
    "# Close the WandB run\n",
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
